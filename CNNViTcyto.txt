CNN base model:
simplecnn_model = models.Sequential()
simplecnn_model.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(64, 64, 1)))
simplecnn_model.add(layers.Flatten())
simplecnn_model.add(layers.Dense(32, activation='relu'))
simplecnn_model.add(layers.Dense(2))

simplecnn_model.compile(optimizer='adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['val_accuracy'])

Performs well, check for over fitting in future work.


ViT base model:

vit_model = vit.vit_b32(
image_size = 64,
activation = 'max',
pretrained = True,
include_top = False,
pretrained_top = False,
classes = 2)

vit_model.trainable = False

  model_list = []
  model_list.append(vit_model)

  model_list.append(tf.keras.layers.Dense(256, activation = 'sigmoid'))

  model_list.append(tf.keras.layers.Dense(128, activation = 'sigmoid'))

  model_list.append(tf.keras.layers.Dense(64, activation = 'relu'))

  model_list.append(tf.keras.layers.Dense(32, activation = 'relu'))

  # model_list.append(tf.keras.layers.Dense(1, activation = 'softmax'))

  model_list.append(tf.keras.layers.Dense(1, activation="sigmoid"))

  model = tf.keras.Sequential(model_list,name='ViT')


  model.compile(optimizer='adam', loss='binary_crossentropy')

  model.fit(train_images, train_labels, epochs=5,
                    validation_data=(test_images, test_labels), batch_size=30)

This performs very poorly so far - pre-training does not fit test data type at all.




